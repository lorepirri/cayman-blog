---
layout: page
title: "Deep Learning - Softmax 함수란"
description: "Deep Learning - Softmax 함수에 대하여 알아보겠다"
categories: machine-learning
tags: softmax
comments: true
published: true
---

인공신경망에서 출력층의 정규화를 위한 함수인 소프트맥스(softmax)함수에 대하여 알아보겠다.


## 소프트맥스 (softmax) 함수란 무엇일까?



뉴런의 출력값에 대하여 class 분류를 위하여 마지막 단계에서 출력값에 대한 **정규화**를 해주는 함수이다.

인물 사진을 예로 들어 보겠다.

사진속 인물이 지금 슬픈 표정인지, 웃는 표정인지, 화난 표정인지 확률적으로 수치화한다고 했을때,

슬픔 (11%), 웃음 (29%), 화남(60%) 화같이 확률적 classification 을 할 때 용이하다.

소프트맥스 함수의 특징은 결과물의 수치의 **합은 언제나 1.0** 이다.



## 소프트맥스 함수의 구현



```python
def softmax(arr):
    arr = np.exp(arr)
    return arr / np.sum(arr)
```



위와같이 매우 간단하게 구현할 수 있다.

다만 exp할때 오버플로우가 나는 경우가 있으니,

argument 의 max 값을 차감해준다.



코드로 보자면,

```python
def softmax(arr):
    m = np.argmax(arr)
    arr = arr - m
    arr = np.exp(arr)
    return arr / np.sum(arr)
```



간단히 예제로 살펴보자면,

```python
import numpy as np
import pandas as pd

a = np.random.uniform(low=0.0, high=10.0, size=3)

def softmax(arr):
    m = np.argmax(arr)
    arr = arr - m
    arr = np.exp(arr)
    return arr / np.sum(arr)

y = softmax(a)
```



결과값

```python
y
array([0.40425513, 0.02291779, 0.57282709])

y.sum()
1.0
```



***참고 문헌: 밑바닥부터 시작하는 딥러닝***

##### #softmax #deep_learning #python









